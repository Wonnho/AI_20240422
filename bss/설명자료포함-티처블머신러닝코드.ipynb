{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "670c6588-cf72-4a32-855b-acc5d7c517f6",
   "metadata": {},
   "source": [
    "### Part1.  모듈설정\n",
    "- Keras는 tensorflow를 설치하면 됨\n",
    "- PIL은 이미지 불러오기등 파이선에서 대표적인 이미지처리모듈(openCV 도 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7698232d-2016-4b5d-b92a-025bfb35dc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 15:30:39.647445: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model  # TensorFlow is required for Keras to work\n",
    "from PIL import Image, ImageOps  # Install pillow instead of PIL\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e5a286-c883-4224-8d9d-ff6a66ef1fe6",
   "metadata": {},
   "source": [
    "### Part2. \n",
    "- home-tf 폴더에 keras_model.h5  모델과 label.txt 파일이 있어야함.\n",
    "- model.summay   / model.weights 로 모델의 정보 확인가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd91fbdc-1aeb-4ae1-9380-b12df004dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"keras_model.h5\", compile=False)\n",
    "class_names = open(\"labels.txt\", \"r\").readlines()\n",
    "#model.summary(), model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3323f9-3f26-4282-96c3-783c51dcf9b3",
   "metadata": {},
   "source": [
    "### Part3. 이미지 읽기 \n",
    "- 반드시 학습한 이미지 크기와 맞아야함.\n",
    "- 학습할때의 정규화 작업도 있어야함.\n",
    "- 그리고  tensor단위로 변경해야함.\n",
    "- 다음과 같이 코드 가능\n",
    "  - image = Image.open(\"test.jpg\").convert(\"RGB\")\n",
    "  - image = Image.open(\"test.jpg\").convert(\"RGB\").resize((224,224)\n",
    "  - image_array=np.array(image)\n",
    "  - data=(image_array.astype(np.float32) / 127.5) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "201b50cb-5e71-4a8e-8ba8-d3b14bbbfd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "image = Image.open(\"test.jpg\").convert(\"RGB\")\n",
    "size = (224, 224)\n",
    "image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n",
    "image_array = np.asarray(image)    # image_array.shape --> 224,224,3\n",
    "normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
    "data[0] = normalized_image_array  # data[0].shape --> 224,224,3   / data.shape --> 1,224,224,3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de462b-ca10-4ef0-9392-26a07d6744d4",
   "metadata": {},
   "source": [
    "## Part4. 모델예측\n",
    "- 2개의 class 에 대한 0번위치, 1번위치에 대한 확률값으로만 출력됨\n",
    "- 다 더해서 1이 되는 softmax 함수가 적용되어 있음.\n",
    "- 가장큰 확률값은 갖는 위치는 np.argmax 함수로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bab38ff4-83b9-42e2-b91c-e08cb72b7746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 782ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.65890354, 0.34109643]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(data)\n",
    "prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "039a870d-0fa4-4bf0-bd43-b115f78164a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.argmax(prediction)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e206599-53fa-4e6e-bd29-8a44f08e0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = class_names[index]\n",
    "confidence_score = prediction[0][index]\n",
    "\n",
    "# Print prediction and confidence score\n",
    "print(\"Class:\", class_name[2:], end=\"\")\n",
    "print(\"Confidence Score:\", confidence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec0718b-7fef-44cd-b511-820c8d214816",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PILLOW "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
